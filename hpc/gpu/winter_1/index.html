<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Getting started with HPC GPU Setup. Configure conda environment specific for GPU based HPC and for deep learning usage. Setup Tensorflow, Keras, PyTorch and imaging-based tools like CellPose, StarDist, and CellProfiler. Configure bash startup specific to GPU based HPC."><meta name=author content="Samir B. Amin"><link href=https://code.sbamin.com/hpc/gpu/winter_1/ rel=canonical><link href=../../cpu/sumner_3/ rel=prev><link href=../image_analysis_cellprofiler_cellpose/ rel=next><link rel=icon href=../../../assets/images/fixed/favicon.ico><meta name=generator content="mkdocs-1.5.2, mkdocs-material-9.2.3"><title>Setting up GPU env - Programming 101</title><link rel=stylesheet href=../../../assets/stylesheets/main.0e669242.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.85d0ee34.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Fira Code"}</style><link rel=stylesheet href=../../../css/timeago.css><link rel=stylesheet href=../../../assets/css/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","UA-307297-1"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","UA-307297-1",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=UA-307297-1",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><!--   <link rel="stylesheet" href="https://code.sbamin.com/../../../assets/stylesheets/main.c296cc61.min.css"> --><meta name=keywords content=hpc,gpu,tensorflow,keras,pytorch,machine_learning,deep_learning,conda,jupyter,segmentation,winter,jax><meta property=og:type content=website><meta property=og:title content="GPU setup · Programming 101"><meta property=og:description content="Getting started with HPC GPU Setup. Configure conda environment specific for GPU based HPC and for deep learning usage. Setup Tensorflow, Keras, PyTorch and imaging-based tools like CellPose, StarDist, and CellProfiler. Configure bash startup specific to GPU based HPC."><meta content=https://code.sbamin.com/hpc/gpu/winter_1/ property=og:url><meta property=og:image content=https://code.sbamin.com/assets/images/fixed/sitelogo.png><meta property=og:image:type content=image/png><meta property=og:image:width content=256><meta property=og:image:height content=256><meta name=twitter:card content=summary><meta name=twitter:site content=@sbamin><meta name=twitter:creator content=@sbamin><meta name=twitter:title content="GPU setup · Programming 101"><meta name=twitter:description content="Getting started with HPC GPU Setup. Configure conda environment specific for GPU based HPC and for deep learning usage. Setup Tensorflow, Keras, PyTorch and imaging-based tools like CellPose, StarDist, and CellProfiler. Configure bash startup specific to GPU based HPC."><meta name=twitter:image content=https://code.sbamin.com/assets/images/fixed/sitelogo.png><meta name=twitter:image:alt content="webpage banner or site logo"></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=blue data-md-color-accent=indigo> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#login-to-gpu-hpc class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="Programming 101" class="md-header__button md-logo" aria-label="Programming 101" data-md-component=logo> <img src=../../../assets/images/fixed/sitelogo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Programming 101 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Setting up GPU env </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=blue data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=teal data-md-color-accent=light-green aria-label="Switch to light mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/sbamin/code101 title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33.85 0 1.71.11 2.5.33 1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2Z"/></svg> </div> <div class=md-source__repository> sbamin/code101 </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../blog/ class=md-tabs__link> Blog </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Getting started with HPC </a> </li> <li class=md-tabs__item> <a href=../../../tags/ class=md-tabs__link> Tags </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Programming 101" class="md-nav__button md-logo" aria-label="Programming 101" data-md-component=logo> <img src=../../../assets/images/fixed/sitelogo.png alt=logo> </a> Programming 101 </label> <div class=md-nav__source> <a href=https://github.com/sbamin/code101 title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33.85 0 1.71.11 2.5.33 1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2Z"/></svg> </div> <div class=md-source__repository> sbamin/code101 </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=../../../blog/ class="md-nav__link "> <span class=md-ellipsis> Blog </span> </a> <label class="md-nav__link " for=__nav_2> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../blog/archive/2023/ class=md-nav__link> <span class=md-ellipsis> 2023 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../blog/category/howto/ class=md-nav__link> <span class=md-ellipsis> HowTo </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> Getting started with HPC </span> </a> <label class="md-nav__link " for=__nav_3> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Getting started with HPC </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> CPU Computing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> CPU Computing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../cpu/sumner_1/ class=md-nav__link> <span class=md-ellipsis> Part 1 </span> </a> </li> <li class=md-nav__item> <a href=../../cpu/sumner_2/ class=md-nav__link> <span class=md-ellipsis> Part 2 </span> </a> </li> <li class=md-nav__item> <a href=../../cpu/sumner_3/ class=md-nav__link> <span class=md-ellipsis> Part 3 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3 checked> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> GPU Computing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> GPU Computing </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> GPU setup </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> GPU setup </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#login-to-gpu-hpc class=md-nav__link> Login to GPU HPC </a> </li> <li class=md-nav__item> <a href=#create-a-gpu-env-rey class=md-nav__link> Create a GPU env rey </a> <nav class=md-nav aria-label="Create a GPU env rey"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install-essentials class=md-nav__link> Install essentials </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#loading-gpu-env class=md-nav__link> Loading GPU env </a> <nav class=md-nav aria-label="Loading GPU env"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#check-cuda-drivers class=md-nav__link> Check CUDA drivers </a> </li> <li class=md-nav__item> <a href=#setup-gpu-env-as-modulefile class=md-nav__link> Setup GPU env as Modulefile </a> </li> <li class=md-nav__item> <a href=#jupyter-kernels class=md-nav__link> Jupyter kernels </a> </li> <li class=md-nav__item> <a href=#renviron-setup class=md-nav__link> Renviron setup </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optional-setup class=md-nav__link> Optional Setup </a> <nav class=md-nav aria-label="Optional Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensorboard class=md-nav__link> Tensorboard </a> </li> <li class=md-nav__item> <a href=#tensorrt class=md-nav__link> TensorRT </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#test-gpu-functionality class=md-nav__link> Test GPU functionality </a> <nav class=md-nav aria-label="Test GPU functionality"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#test-tensorflow-and-keras class=md-nav__link> Test Tensorflow and Keras </a> </li> <li class=md-nav__item> <a href=#test-pytorch class=md-nav__link> Test PyTorch </a> </li> <li class=md-nav__item> <a href=#test-tensorrt class=md-nav__link> Test TensorRT </a> </li> <li class=md-nav__item> <a href=#dask class=md-nav__link> Dask </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#image-classification class=md-nav__link> Image Classification </a> </li> <li class=md-nav__item> <a href=#update-bash-startup class=md-nav__link> Update bash startup </a> </li> <li class=md-nav__item> <a href=#done class=md-nav__link> Done! </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../image_analysis_cellprofiler_cellpose/ class=md-nav__link> <span class=md-ellipsis> Image analysis on GPU-based HPC </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#login-to-gpu-hpc class=md-nav__link> Login to GPU HPC </a> </li> <li class=md-nav__item> <a href=#create-a-gpu-env-rey class=md-nav__link> Create a GPU env rey </a> <nav class=md-nav aria-label="Create a GPU env rey"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install-essentials class=md-nav__link> Install essentials </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#loading-gpu-env class=md-nav__link> Loading GPU env </a> <nav class=md-nav aria-label="Loading GPU env"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#check-cuda-drivers class=md-nav__link> Check CUDA drivers </a> </li> <li class=md-nav__item> <a href=#setup-gpu-env-as-modulefile class=md-nav__link> Setup GPU env as Modulefile </a> </li> <li class=md-nav__item> <a href=#jupyter-kernels class=md-nav__link> Jupyter kernels </a> </li> <li class=md-nav__item> <a href=#renviron-setup class=md-nav__link> Renviron setup </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optional-setup class=md-nav__link> Optional Setup </a> <nav class=md-nav aria-label="Optional Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tensorboard class=md-nav__link> Tensorboard </a> </li> <li class=md-nav__item> <a href=#tensorrt class=md-nav__link> TensorRT </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#test-gpu-functionality class=md-nav__link> Test GPU functionality </a> <nav class=md-nav aria-label="Test GPU functionality"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#test-tensorflow-and-keras class=md-nav__link> Test Tensorflow and Keras </a> </li> <li class=md-nav__item> <a href=#test-pytorch class=md-nav__link> Test PyTorch </a> </li> <li class=md-nav__item> <a href=#test-tensorrt class=md-nav__link> Test TensorRT </a> </li> <li class=md-nav__item> <a href=#dask class=md-nav__link> Dask </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#image-classification class=md-nav__link> Image Classification </a> </li> <li class=md-nav__item> <a href=#update-bash-startup class=md-nav__link> Update bash startup </a> </li> <li class=md-nav__item> <a href=#done class=md-nav__link> Done! </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <nav class=md-tags> <a href=../../../tags/#hpc class=md-tag>hpc</a> <a href=../../../tags/#setup class=md-tag>setup</a> <a href=../../../tags/#gpu class=md-tag>gpu</a> <a href=../../../tags/#deep-learning class=md-tag>deep learning</a> <a href=../../../tags/#imaging class=md-tag>imaging</a> <a href=../../../tags/#programming class=md-tag>programming</a> </nav> <a href=https://github.com/sbamin/code101/edit/scratch/web/docs/hpc/gpu/winter_1.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg> </a> <a href=https://github.com/sbamin/code101/blob/scratch/web/docs/hpc/gpu/winter_1.md title="View source of this page - Requires a valid access to github repository" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg> </a> <h1>GPU setup</h1> <p>Winter HPC at JAX is a GPU-based computing cluster and it is powered by <a href=https://www.nvidia.com/en-us/data-center/v100/ >NVIDIA&reg; V100 series</a> GPU cards. If you are working on GPU-based HPC or linux env, following page should guide you on setting up commonly used GPU libraries, e.g., <a href=https://www.tensorflow.org/ >Tensorflow 2</a>, <a href=https://keras.io/about/ >Keras</a>, and <a href=https://pytorch.org/ >PyTorch</a>. GPU setup involves several technical jargon related to hardware compliant libraries, e.g., CUDA toolkit if using NVIDIA marketed GPU cards. I will not go into details of each step here and instead link to installation guide for further details. Knowing such details should be useful while working with deep learning tools and debugging runtime errors.</p> <p>Before starting GPU setup, I expect that you have finished CPU setup, up until <a href=../../cpu/sumner_3/ >Part 3</a>, mainly installing <a href=../../cpu/sumner_2/#create-a-new-env><em>yoda</em> env</a> and <a href=../../cpu/sumner_3/#bash-startup>bash startup sequence</a>.</p> <h2 id=login-to-gpu-hpc>Login to GPU HPC<a class=headerlink href=#login-to-gpu-hpc title="Permanent link">&para;</a></h2> <p>First, let's move away from CPU HPC, aka Sumer HPC at JAX, and instead login to GPU HPC, i.e., Winter HPC at JAX. We have a common linux base operating system (OS), i.e., Cent OS 7 and a user home directory for both HPCs, hence I will have an identical bash env - via <a href=../../cpu/sumner_3/#bash-startup>bash startup sequence</a> - in Winter as of Sumner.</p> <details class=info> <summary>home directory and operating system</summary> <p>If you have a separate OS and a home directory for CPU and GPU HPCs, you need to start from a scratch in setting up GPU HPC, i.e., initial setup is identical to <a href=../../cpu/sumner_1/ >CPU setup</a>, preferably all three parts or at least installing <em>yoda</em> env and bash startup sequence.</p> <p>If you have an identical home directory but different OS, e.g., Cent OS 6 on CPU HPC and Cent OS 7 on GPU HPC, that's a bad system design in my view as it will be challenging - at least to me - to separate software compilation libraries by modifying PATH, LD_LIBRARY_PATH, etc. and configuration locations, e.g., ~/.local and ~/.config under the shared bash env.</p> </details> <ul> <li>Login to Winter HPC</li> </ul> <div class=highlight><pre><span></span><code>ssh<span class=w> </span>winter
</code></pre></div> <blockquote> <p>If you have set <a href=../../cpu/sumner_3/#bash-startup>bash startup sequence</a> earlier, you should expect ~identical<sup id=fnref:diff_bash_env><a class=footnote-ref href=#fn:diff_bash_env>1</a></sup> bash env, including ordering of paths (output of <code>echo $PATH</code>) between CPU and GPU HPCs.</p> </blockquote> <ul> <li>Start an interactive job, so that we can use compute and not login node for setup/ This is to avoid our setup being potentially killed on the login node due to compute and/or memory intensive commands we will run during setup.</li> </ul> <div class=highlight><pre><span></span><code><span class=c1>## interactive job command may vary across HPCs</span>
<span class=c1>## requesting partition: gpu with one gpu core</span>
srun<span class=w> </span>--job-name<span class=o>=</span>gpusetup<span class=w> </span>--qos<span class=o>=</span>dev<span class=w> </span>--time<span class=o>=</span><span class=m>08</span>:00:00<span class=w> </span>--mem<span class=o>=</span>8G<span class=w> </span>--nodes<span class=o>=</span><span class=m>1</span><span class=w> </span>--ntasks<span class=o>=</span><span class=m>2</span><span class=w> </span>--mail-type<span class=o>=</span>FAIL<span class=w> </span>--export<span class=o>=</span>all<span class=w> </span>--gres<span class=w> </span>gpu:1<span class=w> </span>--pty<span class=w> </span>bash<span class=w> </span>--login
</code></pre></div> <blockquote> <p>Notice that I now use <code>bash --login</code> over <code>bash</code> to force interactive login. Details under <a href=../../cpu/sumner_3/#bash-startup>bash startup sequence</a>.</p> </blockquote> <p>Once you are in the interactive session, bash prompt will change to <em>user@winter200</em> or some other number than the original login node. We are going to create a new and dedicated conda env for GPU HPC, named <em>rey</em>. That said, we can use previously setup conda env for CPU HPC here too!</p> <ul> <li>For example, to start R session on GPU HPC:</li> </ul> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>activate<span class=w> </span>yoda
R
</code></pre></div> <p>You should be able to interact with R same as you do on CPU HPC, as long as both HPCs have shared storage paths and an identical OS.</p> <div class="admonition warning"> <p class=admonition-title>Avoid managing conda env across HPCs</p> <p>While it should not matter if you are managing conda env on CPU or GPU HPC, e.g., installing or upgrading conda packages, I prefer to manage all of <a href=../../cpu/sumner_2/#create-a-new-env>CPU optimized conda envs</a>, i.e., <em>base</em>, <em>yoda</em>, <em>leia</em>, etc. from Sumner (CPU) HPC. Accordingly, I will use Winter GPU HPC to manage GPU-optimized conda env, i.e., <em>rey</em> and <em>ben</em>. This is particularly important for managing GPU env as CUDA and other GPU-specific libraries are not available on CPU HPC and so, installing or upgrading GPU packages may fail if you use CPU HPC to manage GPU env.</p> </div> <p>Let's deactivate <em>yoda</em> and return to <em>base</em> env in the Winter HPC.</p> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>deactivate
</code></pre></div> <h2 id=create-a-gpu-env-rey>Create a GPU env <em>rey</em><a class=headerlink href=#create-a-gpu-env-rey title="Permanent link">&para;</a></h2> <p>Now, we are going to install <em>sizable</em> (3 GB or more) worth of packages into a new conda env, <em>rey</em>. These packages form core of deep learning or specifically provide set of algorithms to employ artificial neural network based machine learning.</p> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>create<span class=w> </span>-c<span class=w> </span>conda-forge<span class=w> </span>-c<span class=w> </span>pytorch<span class=w> </span>-n<span class=w> </span>rey<span class=w> </span><span class=nv>python</span><span class=o>=</span><span class=m>3</span>.9<span class=w> </span>tensorflow-gpu<span class=w> </span>keras<span class=w> </span>pytorch<span class=w> </span>torchvision<span class=w> </span>torchaudio<span class=w> </span><span class=nv>cudatoolkit</span><span class=o>=</span><span class=m>11</span>.1.1<span class=w> </span>cudatoolkit-dev<span class=o>=</span><span class=m>11</span>.1.1<span class=w> </span>scikit-learn<span class=w> </span>xgboost<span class=w> </span>r-base<span class=o>=</span><span class=m>4</span>.1.1<span class=w> </span>r-tensorflow<span class=w> </span>r-keras<span class=w> </span>r-tfdatasets<span class=w> </span>tensorflow-hub<span class=w> </span>cupy<span class=w> </span>dask<span class=w> </span>dask-ml<span class=w> </span>pyopencl<span class=w> </span>pocl<span class=w> </span>

<span class=c1>## lazy way to check if above command had any errors.</span>
<span class=c1>## should return 0, meaning successful execution of</span>
<span class=c1>## the most recent previous command.</span>
<span class=nb>echo</span><span class=w> </span><span class=nv>$?</span>
</code></pre></div> <p><mark>Before running above command, please know what we are installing here:</mark></p> <ul> <li>Create a new conda env, <em>rey</em> for GPU-based HPC.</li> <li>Install all packages with the highest preference from <em>conda-forge</em> channel followed by <em>pytorch</em>. <a href=https://pytorch.org>PyTorch</a> is a a commonly used deep learning library and PyTorch team distributes some of dependencies with their own conda channel.</li> <li>For all practical purposes, we will try to keep <em>rey</em> env similar to <em>yoda</em> env while adding GPU support in <em>rey</em>. Accordingly, we need to ensure that we are using similar <code>major.minor</code> version for Python and R - two major programming languages that I use on daily basis.<ul> <li>I am using python 3.10 in <em>yoda</em>. However, python 3.10 support is <a href="https://github.com/pytorch/pytorch/issues/66424 for PyTorch">not yet available</a>, a commonly used deep learning library. Hence, I am specifying <code>python=3.9</code> to ensure that <code>mamba create</code> will do the best to keep that version. You may try using the same python version as you have in <em>yoda</em> env, and check if <code>mamba create ...</code> command above throws an error regarding conflicting versions. If it does, update <code>=3.XX</code> to a one lower minor version until mamba allows you to create a new env, <em>rey</em>.</li> <li>Same logic for R by using <code>r-base=4.1.1</code> to match R version in <em>yoda</em> env. Please read <strong>important notes below</strong> on using R packages across two or more conda envs.</li> </ul> </li> <li>Install popular ML frameworks with GPU support: <a href=https://www.tensorflow.org/install/gpu>Tensorflow 2</a>, <a href=https://keras.io/getting_started>Keras</a>, and <a href=https://pytorch.org/get-started/locally>PyTorch</a>. Keras now ships with Tensorflow 2 and so specifying keras in command above is optional.<ul> <li>Notice that unlike restricting version for Python and R (to match with that in <em>yoda</em> env), we are not specifying versions for any of ML libraries. Doing so has one drawback that in rare cases, conda may end up installing an older but compatible version (with our Python and R) of one or more ML libraries. If this happens and you are in need of the latest ML library, you have an option to create yet another conda env to install the most recent ML library at the cost of possibly installing a different version of Python and R than one in <em>yoda</em> env.</li> </ul> </li> <li> <p>CUDA toolkit is the heart of leveraging GPU support on Winter HPC. Using conda, we are installing CUDA toolkit and related development kit to install NVIDIA&reg; <a href=https://developer.nvidia.com/cudnn>cuDNN library</a>. However, we will <strong>ensure - by appending, <code>=11.1.1</code> to a package - that CUDA toolkit version must match that of system installed CUDA drivers by HPC staff</strong>. If there is a mismatch, GPU hardware (NVIDIA V100 card) may fail to recognize our instructions (commands) to perform machine learning analysis.</p> <ul> <li>For Winter HPC at JAX, I am using <mark>CUDA 11.1.1</mark> based on available drivers in Winter HPC. These drivers are typically configured using HPC modules and you can list those using <code>module available</code> and then list details for a specific drivers, e.g, <code>module show cuda11.1/toolkit/11.1.1</code>. Besides toolkit, HPC staff also provides following other core drivers which may be required for installing or running a specific GPU-compiled package. For now, I am not loading any of these default modules and instead relying on conda-managed (and minimal) packages.</li> </ul> <div class=highlight><pre><span></span><code>cuda11.1/blas/11.1.1
cuda11.1/fft/11.1.1
cuda11.1/nsight/11.1.1
cuda11.1/profiler/11.1.1
cuda11.1/toolkit/11.1.1 
</code></pre></div> </li> <li> <p>We will also install <a href=https://scikit-learn.org>scikit-learn</a> and <a href=https://xgboost.readthedocs.io/en/stable/ >XGBoost</a>, two popular libraries for machine learning at-large. </p> </li> <li>Then, I will install GPU support for R language and a few packages for using <a href=https://tensorflow.rstudio.com/tutorials/ >Tensorflow for R</a>.<ul> <li>We have earlier <a href=../../cpu/sumner_2/#installing-r>installed R</a> in <em>yoda</em> but we cannot use it in <em>rey</em> env. To leverage R for machine (and deep) learning, I will install the identical R version, i.e. 4.1.1 in conda env, <em>rey</em>. That way, I can use most of R packages from <em>yoda</em> (CPU-based) env for use in <em>rey</em> (GPU-based) env.</li> </ul> </li> </ul> <div class="admonition warning"> <p class=admonition-title>Careful sharing R packages across two or more conda envs</p> <p>Do note that some R packages requires additional packages (libraries) to be installed in the respective conda env, e.g., rJava requires <code>java</code> from <em>yoda</em> env and may not work with <em>rey</em> env. In such cases, use <code>mamba install</code> to install such packages in <em>rey</em> while on GPU env but <em>avoid</em> running <code>install.packages</code> command from a R session running in <em>rey</em> env. Why?</p> <p>I have briefly touched on this issue in <a href=../../cpu/sumner_3/#tips-on-compiling-packages>Part 3: Tips on compiling packages</a>. If we use <code>install.packages</code> from <em>rey</em> env, it will end up installing the same package, e.g., <code>rJava</code> and perhaps, all of its dependencies into the same library path as of <em>yoda</em> env, i.e., as defined by first entry of <code>.libPaths()</code>. That is a recipe for warnings and errors because doing so will inevitably mix up library dependencies between two different conda envs, each optimized for CPU and GPU.</p> <p>There is a solution though! We can update <code>.libPaths()</code> for <em>rey</em> on-the-fly when we activate or deactivate <em>rey</em> env (<a href=#renviron-setup>explained later</a>) and that way, we can ensure that <code>install.packages</code> <em>should</em> install packages in <em>rey</em> specific R package path. I say "should" as R may end up updating packages in any of user-writable paths, even if the path is set as a second or lower preference.</p> <p>In nutshell, to avoid breaking R in multiple conda env, use <code>mamba install</code> or <code>mamba update</code> over R <code>install.packages()</code> when possible.</p> </div> <ul> <li>I will also install a few additional packages for image classification and related machine learning purpose. These are: <a href=https://cupy.dev>cupy</a>, <a href=https://docs.dask.org>dask</a>, <a href=https://ml.dask.org>dask-ml</a>, <a href=https://documen.tician.de/pyopencl>pyopencl, and pocl</a>. A notable exception is that I am not installing <a href=https://github.com/Theano/Theano>Theano</a> which is not under active development but now forked as <a href=https://github.com/aesara-devs/aesara>Aesara</a>.</li> <li>I am installing all major packages at once to ensure package dependencies are not in conflict and we have a stable GPU env.</li> <li>While some of packages, e.g., r-tensorflow may work on CPU-based HPC too, I would recommend to use this conda env only on the GPU-based HPC as most of packages require GPU support.</li> </ul> <h3 id=install-essentials>Install essentials<a class=headerlink href=#install-essentials title="Permanent link">&para;</a></h3> <p>I use following tools in routine and have installed these tools into <em>yoda</em> env - a default for CPU-based HPC<sup id=fnref:rlibs><a class=footnote-ref href=#fn:rlibs>2</a></sup>. Similarly, I am installing in these tools here in <em>rey</em> env too for GPU-based HPC.</p> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>install<span class=w> </span>-c<span class=w> </span>conda-forge<span class=w> </span>wget<span class=w> </span>curl<span class=w> </span>rsync<span class=w> </span>libiconv<span class=w> </span>parallel<span class=w> </span>ipyparallel<span class=w> </span>git<span class=w> </span>rsync<span class=w> </span>vim<span class=w> </span>globus-cli<span class=w> </span>tmux<span class=w> </span>screen<span class=w> </span><span class=nv>openjdk</span><span class=o>=</span><span class=m>11</span>.0<span class=w> </span>r-rjava<span class=w> </span>matplotlib<span class=w> </span>r-reticulate<span class=w> </span>rpy2
</code></pre></div> <blockquote> <p>For java (openjdk), prefer using the same version as in <em>yoda</em>, e.g., restrict java major.minor version to be 11.0 but allow a different patch (11.0.1 or 11.0.2,...).</p> </blockquote> <h2 id=loading-gpu-env>Loading GPU env<a class=headerlink href=#loading-gpu-env title="Permanent link">&para;</a></h2> <p>Once we have <em>rey</em> env ready, we can check type of GPU, CUDA drivers, etc. We should also ensure that we configure CUDA drivers and related env variables correctly, so future installations of GPU tools, like TensorRT recognize CUDA related variables and work correctly.</p> <h3 id=check-cuda-drivers>Check CUDA drivers<a class=headerlink href=#check-cuda-drivers title="Permanent link">&para;</a></h3> <ul> <li>Let's activate <em>rey</em> and power up GPU!</li> </ul> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>activate<span class=w> </span>rey
</code></pre></div> <ul> <li>Check NVIDIA driver version</li> </ul> <div class=highlight><pre><span></span><code>nvcc<span class=w> </span>--version
</code></pre></div> <div class=highlight><pre><span></span><code>nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Oct_12_20:09:46_PDT_2020
Cuda compilation tools, release 11.1, V11.1.105
Build cuda_11.1.TC455_06.29190527_0
</code></pre></div> <ul> <li>Check GPU usage activity on the compute node using <code>nvidia-smi</code>. This command is from a system-installed cuda libraries, typically under <code>/usr/bin</code> or <code>/usr/local/bin</code>. On Winter HPC at JAX, it is only available on compute nodes and not on a login node.</li> </ul> <h3 id=setup-gpu-env-as-modulefile>Setup GPU env as Modulefile<a class=headerlink href=#setup-gpu-env-as-modulefile title="Permanent link">&para;</a></h3> <p>Unfortunately, conda installed CUDA toolkit is not a full CUDA installation and it does not set any of CUDA related bash env variables, especially <code>CUDA_PATH</code>, <code>CUDA_HOME</code>, <code>CUDNN_PATH</code> variables. <a class="magiclink magiclink-github magiclink-issue" href=https://github.com/conda/conda/issues/7757 title="GitHub Issue: conda/conda #7757">conda/conda#7757</a> Since I have installed the identical cuda toolkit (v11.1.1) in <em>rey</em> conda env to the one managed by out HPC admins, i.e., <code>module show cuda11.1/toolkit/11.1.1</code>, I will <a href=../../cpu/sumner_3/#modules>create a module file</a> that includes combination of env variables from both of these toolkits. That way, I can load this module during <a href=#update-bash-startup>bash startup</a> such that the module will configure GPU env only on the Winter (GPU) HPC and not on the Sumner (CPU) HPC.</p> <ul> <li>Create an empty local directory structure to store user-installed GPU libraries, e.g., configs related to CUPTI, etc.</li> </ul> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>&quot;</span><span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
mkdir<span class=w> </span>-p<span class=w> </span>gpu/11.1.1/local
</code></pre></div> <ul> <li>Following command will create directory scaffold similar to /usr/local env</li> </ul> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>&quot;</span>/gpu/11.1.1/local<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
mkdir<span class=w> </span>-p<span class=w> </span><span class=o>{</span>bin,etc,include,lib,lib64,libexec,share/<span class=o>{</span>doc,info,locale,man/<span class=o>{</span>man1,man3<span class=o>}}}</span>
</code></pre></div> <ul> <li>Create a module file at "${HPCMODULES}"</li> </ul> <div class=highlight><pre><span></span><code>mkdir<span class=w> </span>-p<span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCMODULES</span><span class=si>}</span><span class=s2>&quot;</span>/gpu
<span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCMODULES</span><span class=si>}</span><span class=s2>&quot;</span>/gpu

<span class=c1>## create a module file that matches CUDA version.</span>
touch<span class=w> </span><span class=m>11</span>.1.1
</code></pre></div> <ul> <li>I have placed GPU configurations from both, admin installed CUDA drivers and GPU packages that I just have installed above. You may need to consult your HPC team to get an idea on configurations that you may able override with conda installed cuda toolkit.</li> </ul> <div class="admonition tip"> <p class=admonition-title>Example modulefiles for GPU HPC</p> <p>My gpu modulefile are at <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"/></svg></span> <a href=https://github.com/sbamin/code101/tree/main/confs/hpc/modules/def>/confs/hpc/modules/def</a></p> </div> <ul> <li>Once we have a modulefile ready, we can load custom gpu env using <code>module load gpu/11.1.1</code>.</li> <li>Notice change in PATH, LD_LIBRARY_PATH, and related env variables. For now, you will notice that <code>"${CONDA_PREFIX}"/bin</code> is pushed behind other cuda related paths we have configured using modulefile. Since I prefer to have <code>"${CONDA_PREFIX}"/bin</code> take precedence over rest of <code>$PATH</code> contents, I will reset PATH such that <code>"${CONDA_PREFIX}"/bin</code>, i.e., <code>../envs/rey/bin</code> in Winter HPC, will take precedence over other paths that we are loading via above modulefile. See <a href=#update-bash-startup>bash startup</a> section for details.</li> </ul> <h3 id=jupyter-kernels>Jupyter kernels<a class=headerlink href=#jupyter-kernels title="Permanent link">&para;</a></h3> <p>Let's install Python and R jupyter kernels for <em>rey</em> with <a href=../../cpu/sumner_2/#python-kernel>configuration</a> similar to that for <em>yoda</em> env.</p> <ul> <li>First, we will install required packages. Here, I am not interested in installing bash_kernel as I did with <em>yoda</em> as I rarely use bash kernel and rather prefer terminal. If installing reticulate and rpy2 packages throw warnings about potential upgrade or downgrade of existing packages in <em>rey</em> env, please <strong>do not ignore warnings</strong> and instead <a href=../../cpu/sumner_2/#reticulate-r-package>follow steps under installing respective packages in <em>yoda</em> env</a>.</li> </ul> <div class=highlight><pre><span></span><code>mamba install -c conda-forge ipykernel r-irkernel r-reticulate rpy2
</code></pre></div> <ul> <li>Setup Python jupyter kernel for <em>rey</em></li> </ul> <div class=highlight><pre><span></span><code>python<span class=w> </span>-m<span class=w> </span>ipykernel<span class=w> </span>install<span class=w> </span>--user<span class=w> </span>--name<span class=w> </span>rey_py39<span class=w> </span>--display-name<span class=w> </span><span class=s2>&quot;rey_py39&quot;</span>

<span class=c1>## confirm that installation exited without any error</span>
<span class=c1>## this should return 0 for successful installation</span>
<span class=nb>echo</span><span class=w> </span><span class=nv>$?</span>
</code></pre></div> <ul> <li>Setup R jupyter kernel for <em>rey</em></li> </ul> <div class=highlight><pre><span></span><code><span class=nf>library</span><span class=p>(</span><span class=n>IRkernel</span><span class=p>)</span>
<span class=nf>installspec</span><span class=p>(</span><span class=n>name</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s>&quot;rey_r41&quot;</span><span class=p>,</span><span class=w> </span><span class=n>displayname</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s>&quot;rey_r41&quot;</span><span class=p>,</span><span class=w> </span><span class=n>user</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=kc>TRUE</span><span class=p>)</span>

<span class=c1>## quit R session</span>
<span class=nf>q</span><span class=p>(</span><span class=n>save</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s>&quot;no&quot;</span><span class=p>)</span>
</code></pre></div> <div class="admonition warning"> <p class=admonition-title>Configure Python and R kernel loading for <em>rey</em></p> <p>Don't forget to <a href=../../cpu/sumner_2/#kernel-loading>tweak kernel loading</a> as we did for <em>yoda</em> env else you may encounter issues running GPU-based packages in JupyterLab env.</p> <p>Pro Tip: You can use conditional expression in kernel wrapper, so kernel can only load on GPU-enabled HPC.</p> <div class=highlight><pre><span></span><code><span class=k>if</span><span class=w> </span><span class=o>[[</span><span class=w> </span><span class=s2>&quot;</span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2>&quot;</span><span class=w> </span>!<span class=o>=</span><span class=w> </span>*<span class=s2>&quot;winter&quot;</span>*<span class=w> </span><span class=o>]]</span><span class=p>;</span><span class=w> </span><span class=k>then</span>
<span class=w>    </span><span class=nb>echo</span><span class=w> </span>-e<span class=w> </span><span class=s2>&quot;ERROR: Invalid hostname\nThis kernel works only on winter HPC\n&quot;</span><span class=w> </span>&gt;<span class=p>&amp;</span><span class=m>2</span>
<span class=w>    </span><span class=nb>exit</span><span class=w> </span><span class=m>1</span>
<span class=k>else</span>
<span class=w>    </span><span class=c1>#### Activate CONDA in subshell ####</span>
<span class=w>    </span><span class=c1>## Read https://github.com/conda/conda/issues/7980</span>
<span class=w>    </span><span class=nv>CONDA_BASE</span><span class=o>=</span><span class=k>$(</span>conda<span class=w> </span>info<span class=w> </span>--base<span class=k>)</span><span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
<span class=w>    </span><span class=nb>source</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>CONDA_BASE</span><span class=si>}</span><span class=s2>&quot;</span>/etc/profile.d/conda.sh<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
<span class=w>    </span>conda<span class=w> </span>activate<span class=w> </span>rey
<span class=w>    </span><span class=c1>#### END CONDA SETUP ####</span>

<span class=w>    </span><span class=c1>## Load additional CUDA drivers, toolkit, etc.</span>
<span class=w>    </span><span class=c1>## if applicable prior to initializing kernel</span>
<span class=w>    </span><span class=c1># module load cuda11.1/toolkit/11.1.1</span>

<span class=w>    </span><span class=c1>##... rest of kernel setup as explained earlier.</span>
</code></pre></div> </div> <h3 id=renviron-setup>Renviron setup<a class=headerlink href=#renviron-setup title="Permanent link">&para;</a></h3> <p>As explained above in the warning box, be careful installing packages using R from more than one conda envs and instead prefer using <code>mamba install</code> or <code>mamba update</code> to manage R packages.</p> <p>When we start R, it reads <em>~/.Renviron</em> file or takes precedence based on order as detailed on <a href=https://cran.r-project.org/web/packages/startup/vignettes/startup-intro.html>CRAN - startup</a> webpage. Accordingly, we will create a <em>rey</em> env-specific R Renviron file such that loading R in <em>rey</em> env will use rey specific library path to install new packages<sup id=fnref:warnrpkg><a class=footnote-ref href=#fn:warnrpkg>3</a></sup>, and will not install those under a default library path for <em>yoda</em> that we specified <a href=../../cpu/sumner_2/#setup-rprofile-and-renviron>earlier in the setup</a>.</p> <ul> <li>Let's create an empty directory to store <em>rey</em> env specific user R packages.</li> </ul> <div class=highlight><pre><span></span><code>mkdir<span class=w> </span>-p<span class=w> </span>/projects/verhaak-lab/amins/hpcenv/opt/R/pkgs/rey4.1
</code></pre></div> <ul> <li>Create an env specific config directory at the place you like and create a Renviron file inside it.</li> </ul> <div class=highlight><pre><span></span><code>mkdir<span class=w> </span>-p<span class=w> </span>/projects/verhaak-lab/amins/hpcenv/opt/R/confs/rey
<span class=nb>cd</span><span class=w> </span>/projects/verhaak-lab/amins/hpcenv/opt/R/confs/rey

<span class=c1>## create a Renviron file</span>
nano<span class=w> </span>Renviron
</code></pre></div> <ul> <li>Add following to Renviron file, i.e., we take the <code>R_LIBS</code> path from <em>~/.Renviron</em> file we <a href=../../cpu/sumner_2/#setup-rprofile-and-renviron>created earlier</a>, and then <strong>prefix</strong> <em>rey</em> env specific paths to it. Here, <em>rey</em> env path consist of two parts:<ul> <li>First, <em>/projects/verhaak-lab/amins/hpcenv/opt/R/pkgs/rey4.1</em> is a newly created custom path where <code>install.packages</code> command can install new packages while working in <em>rey</em> but not <em>yoda</em> env.</li> <li>Second, <em>rey</em> env default R library path that we got from <code>.libPaths()</code> output: <em>/projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/lib/R/library</em>. This path is used by <code>mamba install</code> or <code>mamba update</code> for managing R packages.</li> </ul> </li> </ul> <div class=highlight><pre><span></span><code><span class=n>R_LIBS</span><span class=o>=</span><span class=s>&quot;</span><span class=err>/projects/verhaak-lab/amins/hpcenv/opt/R/pkgs/rey4.1:/projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/lib/R/library:/projects/verhaak-lab/amins/hpcenv/opt/R/pkgs/4.1:/projects/verhaak-lab/amins/hpcenv/mambaforge/envs/yoda/lib/R/library</span>
</code></pre></div> <ul> <li>Now setup a custom loading of Renviron for <em>rey</em> env. This will make sure that R environ will switch/revert every time conda env, <em>rey</em> is loaded/unloaded via <code>mamba activate/deactivate</code> command.</li> </ul> <div class="admonition tip"> <p class=admonition-title>Example activate.d or deactivate.d scripts to manage conda envs</p> <p>You can view example scripts per respective conda env at <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"/></svg></span> <a href=https://github.com/sbamin/code101/tree/main/confs/hpc/mambaforge/envs>/confs/hpc/mambaforge/envs</a>.</p> </div> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span>/projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/etc/conda

<span class=c1>## create a new file</span>
nano<span class=w> </span>activate.d/activate-r-env.sh
</code></pre></div> <ul> <li>Add following to <em>activate.d/activate-r-env.sh</em></li> </ul> <div class=highlight><pre><span></span><code><span class=ch>#!/usr/bin/env sh</span>

<span class=c1>## Define R_HOME from rey env</span>
<span class=nv>R_HOME</span><span class=o>=</span><span class=s2>&quot;</span><span class=nv>$CONDA_PREFIX</span><span class=s2>/lib/R&quot;</span>
<span class=c1>## override ~/.Renviron which otherwise point to R from yoda env</span>
<span class=nv>R_ENVIRON_USER</span><span class=o>=</span><span class=s2>&quot;/projects/verhaak-lab/amins/hpcenv/opt/R/confs/rey/Renviron&quot;</span>

<span class=nb>export</span><span class=w> </span>R_HOME<span class=w> </span>R_ENVIRON_USER
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>load custom user setup after default setup</p> <p><a href=../../cpu/sumner_3/#bash-startup>bash startup</a> reads file in alphanumeric order. There could be other R setup files, e.g., <em>activate.d/activate-r-base.sh</em>. So, make sure to name custom file(s), e.g., <em>activate-r-env.sh</em> file such that it loads after R specific default files. </p> </div> <ul> <li>Similarly create a <em>deactivate.d/deactivate-r-env.sh</em> to unload custom changes when we do <code>mamba deactivate</code> to turn off <em>rey</em> env.</li> </ul> <div class=highlight><pre><span></span><code>nano<span class=w> </span>deactivate.d/deactivate-r-env.sh
</code></pre></div> <ul> <li>and add following:</li> </ul> <div class=highlight><pre><span></span><code><span class=ch>#!/usr/bin/env sh</span>

<span class=c1>## fall back to pre-existing R env</span>
<span class=nb>unset</span><span class=w> </span>R_HOME<span class=w> </span>R_ENVIRON_USER
</code></pre></div> <div class="admonition info"> <p class=admonition-title>Prefer <code>mamba deactivate</code> followed by <code>mamba activate &lt;env name&gt;</code></p> <p><code>unset</code> command will erase and not restore the matching custom env variables, if any. So, ideally you should do <code>mamba deactivate</code> to turn off <em>rey</em> and then do <code>mamba activate yoda</code> to properly activate <em>yoda</em> env to restore custom set env variables and all of env specific bash startup under respective <em>activate.d/</em> directory. </p> </div> <ul> <li>Now logout and login to winter HPC again. Do <code>mamba activate rey</code> and start R, and type <code>.libPaths()</code>. Now, exit R and type do <code>mamba deactivate</code> followed by <code>mamba activate yoda</code>. Start R and type <code>.libPaths()</code>. Notice difference in R library paths under two R sessions!</li> </ul> <h2 id=optional-setup>Optional Setup<a class=headerlink href=#optional-setup title="Permanent link">&para;</a></h2> <p>Following packages are optional for setup.</p> <h3 id=tensorboard>Tensorboard<a class=headerlink href=#tensorboard title="Permanent link">&para;</a></h3> <p><a href=https://www.tensorflow.org/tensorboard>Tensorboard</a> graphical user interface (GUI) ships with Tensorflow 2 and so does not require additional configuration.</p> <ul> <li>Check version for tensorflow and tensorboard</li> </ul> <div class=highlight><pre><span></span><code><span class=c1>## in rey env</span>
python<span class=w> </span>-c<span class=w> </span><span class=s1>&#39;import tensorflow as tf; print(tf.__version__)&#39;</span><span class=w> </span><span class=c1>#2.6.2 or higher</span>
python<span class=w> </span>-c<span class=w> </span><span class=s1>&#39;import tensorboard as tb; print(tb.__version__)&#39;</span><span class=w> </span><span class=c1>#2.6.0 or higher</span>
</code></pre></div> <ul> <li>Checkout <a href=https://www.tensorflow.org/tensorboard/get_started>getting started guide</a> for more on how to use GUI app. If tensorboard python notebook extension, <code>%load_ext tensorboard</code> fails to initialize tensorboard within notebook, you can manually initialize tensorboard using a terminal command as follows: </li> </ul> <div class=highlight><pre><span></span><code>tensorboard<span class=w> </span>serve<span class=w> </span>--logdir<span class=w> </span>logs<span class=w> </span>--host<span class=w> </span>&lt;IP<span class=w> </span>address<span class=w> </span>to<span class=w> </span><span class=nb>bind</span><span class=w> </span>to&gt;
</code></pre></div> <blockquote> <p>where IP address can be a localhost or <code>hostname -I</code> as long as it is on the secure network. Tensorboard should be accessible at an unsecure http address shown in the output of above command.</p> </blockquote> <ul> <li>To quit tensorboard web server on the terminal, press <span class=keys><kbd class=key-control>Ctrl</kbd><span>+</span><kbd class=key-c>C</kbd></span>.</li> </ul> <h3 id=tensorrt>TensorRT<a class=headerlink href=#tensorrt title="Permanent link">&para;</a></h3> <p><a href=https://developer.nvidia.com/tensorrt>NVIDIA&reg; TensorRT&trade;</a> a software development kit (SDK) for NVIDIA compliant GPU cards. Conda does not provide TensorRT package, so we need to install it <strong>using <a href=https://developer.nvidia.com/tensorrt-getting-started>getting started guide</a> and <a href=https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-tar>installation using tarball</a> instructions</strong>. This requires membership into NVIDIA developer program.</p> <h4 id=installation-steps>Installation steps<a class=headerlink href=#installation-steps title="Permanent link">&para;</a></h4> <ul> <li>Download tarball specific to CUDA and cuDNN version as determined by following commands. </li> </ul> <div class=highlight><pre><span></span><code><span class=c1>## CUDA version, 11.1</span>
nvcc<span class=w> </span>--version
<span class=c1>## cuDNN version 8.2</span>
cat<span class=w> </span><span class=si>${</span><span class=nv>CONDA_PREFIX</span><span class=si>}</span>/include/cudnn_version.h<span class=w> </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>CUDNN_MAJOR<span class=w> </span>-A<span class=w> </span><span class=m>2</span>
</code></pre></div> <ul> <li> <p>Accordingly, I have downloaded following tarball: </p> <ul> <li>TensorRT-8.2.2.1.Linux.x86_64-gnu.cuda-11.4.cudnn8.2.tar.gz</li> </ul> </li> <li> <p>Extract tarball to apps folder and rename path to extracted contents, so that we can load TensorRT as a <a href=../../cpu/sumner_3/#modules>module</a>.</p> </li> </ul> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>&quot;</span>

mkdir<span class=w> </span>-p<span class=w> </span>tensorrt
<span class=nb>cd</span><span class=w> </span>tensorrt

<span class=c1>## place tarball in tensorrt directory and then extract it.</span>
tar<span class=w> </span>xvzf<span class=w> </span>TensorRT-8.2.2.1.Linux.x86_64-gnu.cuda-11.4.cudnn8.2.tar.gz

<span class=c1>## rename extracted directory for consistency on naming modules.</span>
mv<span class=w> </span>TensorRT-8.2.2.1<span class=w> </span><span class=m>8</span>.2.2.1
</code></pre></div> <ul> <li>To install TensorRT, we need to temporarily export TensorRT library path to LD_LIBRARY_PATH. For future logins to GPU HPC, we can then load this path as and when needed using modulefile or permanently insert this into LD_LIBRARY_PATH for GPU HPC using GPU-specific <a href=#update-bash-startup>bash startup</a>.</li> </ul> <div class=highlight><pre><span></span><code><span class=nb>export</span><span class=w> </span><span class=nv>LD_LIBRARY_PATH</span><span class=o>=</span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>/tensorrt/8.2.2.1/lib:</span><span class=si>${</span><span class=nv>LD_LIBRARY_PATH</span><span class=si>}</span><span class=s2>&quot;</span>
</code></pre></div> <ul> <li>Install Python TensorRT wheel file. There are more than one file with different <code>cp3x</code>. I could not figure out what it means and so ended up installing the most recent one, i.e., <code>cp39</code>.</li> </ul> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>&quot;</span>/tensorrt/8.2.2.1/python<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
pip<span class=w> </span>install<span class=w> </span>tensorrt-8.2.2.1-cp39-none-linux_x86_64.whl<span class=w> </span><span class=p>|&amp;</span><span class=w> </span>tee<span class=w> </span>-a<span class=w> </span>tensorrt_8.2.2.1_install.log
</code></pre></div> <details class=info> <summary>Expected output:</summary> <div class=highlight><pre><span></span><code>Processing ./tensorrt-8.2.2.1-cp39-none-linux_x86_64.whl
Installing collected packages: tensorrt
Successfully installed tensorrt-8.2.2.1
</code></pre></div> </details> <ul> <li>Install Python UFF wheel file which is required for working with TensorFlow.</li> </ul> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>&quot;</span>/tensorrt/8.2.2.1/uff<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
pip<span class=w> </span>install<span class=w> </span>uff-0.6.9-py2.py3-none-any.whl<span class=w> </span><span class=p>|&amp;</span><span class=w> </span>tee<span class=w> </span>-a<span class=w> </span>tensorrt_8.2.2.1_install.log
</code></pre></div> <details class=info> <summary>Expected output:</summary> <div class=highlight><pre><span></span><code>Processing ./uff-0.6.9-py2.py3-none-any.whl
Requirement already satisfied: numpy&gt;=1.11.0 in /projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/lib/python3.9/site-packages (from uff==0.6.9) (1.19.5)
Requirement already satisfied: protobuf&gt;=3.3.0 in /projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/lib/python3.9/site-packages (from uff==0.6.9) (3.18.1)
Installing collected packages: uff
Successfully installed uff-0.6.9
</code></pre></div> </details> <div class="admonition tip"> <p class=admonition-title>When to use bash startup versus module file</p> <p>Above installation step should include <code>convert-to-uff</code> in PATH which you can check within output of <code>which convert-to-uff</code>. Since installation has already inserted binaries, e.g., <code>convert-to-uff</code> into bash PATH variable, I will now prefer to setup TensorRT related PATH and LD_LIBRARY_PATH using <a href=#update-bash-startup>bash startup</a> instead of loading TensorRT using module file. Module file works better if installation setup does not alter core bash startup variables like PATH and LD_LIBRARY_PATH.</p> </div> <ul> <li>Install the Python graphsurgeon wheel file.</li> </ul> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>&quot;</span>/tensorrt/8.2.2.1/graphsurgeon<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
pip<span class=w> </span>install<span class=w> </span>graphsurgeon-0.4.5-py2.py3-none-any.whl<span class=w> </span><span class=p>|&amp;</span><span class=w> </span>tee<span class=w> </span>-a<span class=w> </span>tensorrt_8.2.2.1_install.log
</code></pre></div> <details class=info> <summary>Expected output:</summary> <div class=highlight><pre><span></span><code>Processing ./graphsurgeon-0.4.5-py2.py3-none-any.whl
Installing collected packages: graphsurgeon
Successfully installed graphsurgeon-0.4.5
</code></pre></div> </details> <ul> <li>Install the Python onnx-graphsurgeon wheel file.</li> </ul> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>&quot;</span>/tensorrt/8.2.2.1/onnx_graphsurgeon<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
pip<span class=w> </span>install<span class=w> </span>onnx_graphsurgeon-0.3.12-py2.py3-none-any.whl<span class=w> </span><span class=p>|&amp;</span><span class=w> </span>tee<span class=w> </span>-a<span class=w> </span>tensorrt_8.2.2.1_install.log
</code></pre></div> <details class=info> <summary>Expected output:</summary> <div class=highlight><pre><span></span><code>Processing ./onnx_graphsurgeon-0.3.12-py2.py3-none-any.whl
Requirement already satisfied: numpy in /projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/lib/python3.9/site-packages (from onnx-graphsurgeon==0.3.12) (1.19.5)
Collecting onnx
  Downloading onnx-1.10.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.7 MB)
Requirement already satisfied: protobuf in /projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/lib/python3.9/site-packages (from onnx-&gt;onnx-graphsurgeon==0.3.12) (3.18.1)
Requirement already satisfied: six in /projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/lib/python3.9/site-packages (from onnx-&gt;onnx-graphsurgeon==0.3.12) (1.15.0)
Requirement already satisfied: typing-extensions&gt;=3.6.2.1 in /projects/verhaak-lab/amins/hpcenv/mambaforge/envs/rey/lib/python3.9/site-packages (from onnx-&gt;onnx-graphsurgeon==0.3.12) (3.7.4.3)
Installing collected packages: onnx, onnx-graphsurgeon
Successfully installed onnx-1.10.2 onnx-graphsurgeon-0.3.12
</code></pre></div> </details> <h2 id=test-gpu-functionality>Test GPU functionality<a class=headerlink href=#test-gpu-functionality title="Permanent link">&para;</a></h2> <p>Once we have <em>rey</em> env ready, we can test GPU functionality of installed packages. This is not a required step but I like to make sure that I am using GPU and not CPU for computation, e.g., tensorflow and r-keras package may fall back to CPU if it finds missing or badly configured support for GPU.</p> <h3 id=test-tensorflow-and-keras>Test Tensorflow and Keras<a class=headerlink href=#test-tensorflow-and-keras title="Permanent link">&para;</a></h3> <p>I have followed beginner scripts from <a href=https://www.tensorflow.org/tutorials>tensorflow tutorials</a> to test GPU functionality. Similarly, RStudio section on <a href=https://tensorflow.rstudio.com/tutorials/ >Tensorflow for R</a> provides beginners tutorials for testing machine learning using GPU.</p> <h3 id=test-pytorch>Test PyTorch<a class=headerlink href=#test-pytorch title="Permanent link">&para;</a></h3> <p>See details on <a href=https://pytorch.org/get-started/locally/#mac-verification>PyTorch</a> website.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</code></pre></div> <h3 id=test-tensorrt>Test TensorRT<a class=headerlink href=#test-tensorrt title="Permanent link">&para;</a></h3> <div class=highlight><pre><span></span><code><span class=nb>cd</span><span class=w> </span><span class=s2>&quot;</span><span class=si>${</span><span class=nv>HPCAPPS</span><span class=si>}</span><span class=s2>&quot;</span>/tensorrt/8.2.2.1

<span class=c1>## ensure that gpu module is loaded</span>
module<span class=w> </span>load<span class=w> </span>gpu/11.1.1

<span class=nb>cd</span><span class=w> </span>samples/sampleMNIST<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
make<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
<span class=nb>echo</span><span class=w> </span><span class=s2>&quot;make OK&quot;</span>

<span class=nb>cd</span><span class=w> </span>../../data/mnist<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
<span class=c1>## Download MNIST dataset</span>
wget<span class=w> </span>http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
wget<span class=w> </span>http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
wget<span class=w> </span>http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
wget<span class=w> </span>http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz

ls<span class=w> </span>*ubyte.gz<span class=w> </span><span class=p>|</span><span class=w> </span>parallel<span class=w> </span>-j2<span class=w> </span>gunzip<span class=w> </span><span class=o>{}</span>

<span class=nb>cd</span><span class=w> </span>../..<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
./bin/sample_mnist<span class=w> </span>-h<span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=se>\</span>
./bin/sample_mnist<span class=w> </span>--datadir<span class=o>=</span>data/mnist
</code></pre></div> <blockquote> <p>If all goes well, you will see tests passed ok and a predicted digit in <a href=https://en.wikipedia.org/wiki/ASCII_art>ASCII art</a>.</p> </blockquote> <h3 id=dask>Dask<a class=headerlink href=#dask title="Permanent link">&para;</a></h3> <p>Read docs at <a href=http://distributed.dask.org/en/stable/client.html>http://distributed.dask.org/en/stable/client.html</a></p> <h2 id=image-classification>Image Classification<a class=headerlink href=#image-classification title="Permanent link">&para;</a></h2> <p>Optional: Libraries specific to cell segmentation.</p> <ul> <li>I am <strong>creating a new conda env, <em>ben</em></strong> for installing tools related to cell segmentation analysis. These tools require additional set of packages (including installing using <code>pip</code>) and are updated often which together can make <em>rey</em> env unstable over long run. Most of packages are based on package requirements for CellPose tool: <a href=https://github.com/MouseLand/cellpose/blob/master/setup.py>setup.py</a> and <a href=https://github.com/MouseLand/cellpose/blob/master/requirements.txt>requirements.txt</a> file.</li> </ul> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>create<span class=w> </span>-c<span class=w> </span>conda-forge<span class=w> </span>-c<span class=w> </span>pytorch<span class=w> </span>-n<span class=w> </span>ben<span class=w> </span><span class=nv>python</span><span class=o>=</span><span class=m>3</span>.9<span class=w> </span>tensorflow-gpu<span class=w> </span>keras<span class=w> </span>pytorch<span class=w> </span>torchvision<span class=w> </span><span class=nv>cudatoolkit</span><span class=o>=</span><span class=m>11</span>.1.1<span class=w> </span>cudatoolkit-dev<span class=o>=</span><span class=m>11</span>.1.1<span class=w> </span>scikit-learn<span class=w> </span>numpy<span class=w> </span>scipy<span class=w> </span>natsort<span class=w> </span>tifffile<span class=w> </span>tqdm<span class=w> </span>numba<span class=w> </span>torch-optimizer
</code></pre></div> <ul> <li> <p>Before activating <em>ben</em> env, duplicate modulefile, <code>gpu/11.1.1</code> that <a href=#setup-gpu-env-as-modulefile>we created earlier</a> to <code>gpu/11.1.1_ben</code>. Replace conda env name from rey to ben in <code>gpu/11.1.1_ben</code>. This will allow to load a valid GPU env and avoid potential danger of putting <em>rey</em> paths in PATH and LD_LIBRARY_PATH while we work in <em>ben</em> env.</p> </li> <li> <p>Activate <em>ben</em> env</p> </li> </ul> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>activate<span class=w> </span>ben
</code></pre></div> <div class="admonition warning"> <p class=admonition-title>Check for a valid bash env</p> <p>If you notice any of <em>rey</em> env related paths, especially taking precedence over <em>ben</em> env paths, something is wrong and you should check modulefiles above to load conda env specific valid env. Installing cellpose and related package dependencies with <strong>invalid bash env will invariably break the core, <em>rey</em> env</strong>.</p> <div class=highlight><pre><span></span><code>module<span class=w> </span>load<span class=w> </span>gpu/11.1.1_ben

<span class=c1>## These should point to paths related to ben and not rey env.</span>
<span class=nb>echo</span><span class=w> </span><span class=nv>$PATH</span>
<span class=nb>echo</span><span class=w> </span><span class=nv>$LD_LIBRARY_PATH</span>
</code></pre></div> </div> <h4 id=cellpose>Cellpose<a class=headerlink href=#cellpose title="Permanent link">&para;</a></h4> <p>A generalized algorithm for cellular segmentation. <a class="magiclink magiclink-github magiclink-repository" href=https://github.com/MouseLand/cellpose title="GitHub Repository: MouseLand/cellpose">MouseLand/cellpose</a></p> <ul> <li>Not recommended but given many dependencies for cellpose are not available or of conflicting nature using <code>mamba install</code>, I am falling back to <code>pip install</code>.</li> </ul> <div class=highlight><pre><span></span><code>pip<span class=w> </span>install<span class=w> </span>cellpose<span class=o>[</span>all<span class=o>]</span><span class=w> </span><span class=p>|&amp;</span><span class=w> </span>tee<span class=w> </span>-a<span class=w> </span>~/logs/cellpose_install.log
</code></pre></div> <blockquote> <p>In case of errors or unstable env, I can always purge <em>ben</em> env without any impact on <em>rey</em> conda env.</p> </blockquote> <details class=info> <summary>Installation log and warnings, if any</summary> <div class=highlight><pre><span></span><code>Installing collected packages: googleapis-common-protos, pyparsing, numpy, google-crc32c, google-api-core, PyWavelets, pyqt5.sip, PyQt5-Qt5, packaging, opencv-python-headless, networkx, imageio, google-resumable-media, google-cloud-core, fastremap, edt, scikit-image, pyqtgraph, pyqt5, google-cloud-storage, cellpose
  Attempting uninstall: numpy
    Found existing installation: numpy 1.19.5
    Uninstalling numpy-1.19.5:
      Successfully uninstalled numpy-1.19.5

ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.

tensorflow 2.6.2 requires numpy~=1.19.2, but you have numpy 1.21.5 which is incompatible.

Successfully installed PyQt5-Qt5-5.15.2 PyWavelets-1.2.0 cellpose-0.7.2 edt-2.1.1 fastremap-1.12.2 google-api-core-2.4.0 google-cloud-core-2.2.1 google-cloud-storage-2.0.0 google-crc32c-1.3.0 google-resumable-media-2.1.0 googleapis-common-protos-1.54.0 imageio-2.13.5 networkx-2.6.3 numpy-1.21.5 opencv-python-headless-4.5.5.62 packaging-21.3 pyparsing-3.0.6 pyqt5-5.15.6 pyqt5.sip-12.9.0 pyqtgraph-0.11.0rc0 scikit-image-0.19.1
</code></pre></div> </details> <ul> <li>Turns out tensorflow 2 (GPU) works with updated numpy and should not be throw an error.</li> </ul> <div class=highlight><pre><span></span><code>python<span class=w> </span>-c<span class=w> </span><span class=s2>&quot;import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))&quot;</span>
</code></pre></div> <ul> <li>CellPose should now be all set for running in <em>ben</em> env.</li> </ul> <div class=highlight><pre><span></span><code>cellpose<span class=w> </span>--help
</code></pre></div> <h4 id=stardist>Stardist<a class=headerlink href=#stardist title="Permanent link">&para;</a></h4> <p>StarDist - Object Detection with Star-convex Shapes. <a class="magiclink magiclink-github magiclink-repository" href=https://github.com/stardist/stardist title="GitHub Repository: stardist/stardist">stardist/stardist</a></p> <div class=highlight><pre><span></span><code><span class=c1>## in ben env</span>
pip<span class=w> </span>install<span class=w> </span>stardist<span class=w> </span><span class=p>|&amp;</span><span class=w> </span>tee<span class=w> </span>-a<span class=w> </span>stardist_install.log
</code></pre></div> <details class=info> <summary>Installation log and warnings, if any</summary> <div class=highlight><pre><span></span><code>Installing collected packages: python-dateutil, kiwisolver, fonttools, cycler, matplotlib, csbdeep, stardist
Successfully installed csbdeep-0.6.3 cycler-0.11.0 fonttools-4.28.5 kiwisolver-1.3.2 matplotlib-3.5.1 python-dateutil-2.8.2 stardist-0.7.3
</code></pre></div> </details> <ul> <li>To test run, <a href=https://github.com/stardist/stardist>follow example from stardist repo</a>.</li> </ul> <h4 id=cellprofiler>Cellprofiler<a class=headerlink href=#cellprofiler title="Permanent link">&para;</a></h4> <p>Tool for image analysis, <a href=https://cellprofiler.org>cellprofiler.org</a></p> <p>Related bioformats2raw and raw2ometiff were downloaded as standalone binary packages and installed as modules.</p> <p>PS: Cellprofiler has a limited GPU support for now but it may change in the future. <a href=https://forum.image.sc/tag/cellprofiler>Follow Cellprofiler forum</a> for updates. For now, I am installing it in <em>grogu</em> env which is a toy env!</p> <div class=highlight><pre><span></span><code><span class=c1>## login to CPU HPC</span>
ssh<span class=w> </span>sumner<span class=w> </span>
</code></pre></div> <ul> <li>Create <em>grogu</em> conda env</li> </ul> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>create<span class=w> </span>-c<span class=w> </span>conda-forge<span class=w> </span>-c<span class=w> </span>bioconda<span class=w> </span>-n<span class=w> </span>grogu<span class=w> </span>cellprofiler
</code></pre></div> <ul> <li>Run cellprofiler</li> </ul> <div class=highlight><pre><span></span><code>mamba<span class=w> </span>activate<span class=w> </span>grogu

cellprofiler<span class=w> </span>--help
</code></pre></div> <h2 id=update-bash-startup>Update bash startup<a class=headerlink href=#update-bash-startup title="Permanent link">&para;</a></h2> <p>Finally, I am tweaking <a href=../../cpu/sumner_3/#bash-startup>bash startup sequence</a> that we had setup earlier, such that it can allow loading GPU-specific bash env only when we login to Winter GPU HPC and not on Sumner CPU HPC. I have made following changes to bash startup. You can <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"/></svg></span> <a href=https://github.com/sbamin/code101/tree/main/confs/hpc/user_env/ >download my bash startup files here</a>.</p> <ul> <li>Update <code>SET PATH</code> block of <em>~/.bash_profile</em> to reset PATH for Winter GPU. See my notes under <code>elif [[ "$(hostname)" == *"winter"* ]]; then</code> section in <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"/></svg></span> an example <a href=https://github.com/sbamin/code101/blob/main/confs/hpc/user_env/.bash_profile>.bash_profile</a> file.</li> <li>Update <em>~/.profile.d/void/VW01_set_winter_gpu.sh</em> to load Winter specific settings. See more into an example <a href=https://github.com/sbamin/code101/blob/main/confs/hpc/user_env/.profile.d/void/VW01_set_winter_gpu.sh>VW01_set_winter_gpu.sh</a> file.</li> </ul> <p>Logout and login again to Winter HPC. You will see a near identical bash prompt like Sumner HPC, e.g., <code>user@winter-log1</code>. However, when you check <code>echo $PATH</code> output and <code>echo $CONDA_DEFAULT_ENV</code>, you will notice that a default conda env in Winter HPC is now <em>rey</em> while in Sumner HPC, it is <em>base</em> (sometimes called <em>root</em>).</p> <p>Of course, you can revert to base or any other conda env in Winter HPC by doing <code>mamba deactivate</code> (because we changed from base to rey during bash startup) and then <code>mamba activate base</code> (or yoda, or any other env).</p> <p>If you have also setup activate.d/deactivate.d scripts as <a href=#renviron-setup>detailed earlier</a>, you will be able to fine tune loading and unloading of conda env specific to HPC type (CPU or GPU) as well as type of R and GPU-specific configs. See <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M4 1.75C4 .784 4.784 0 5.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 14.25 15h-9a.75.75 0 0 1 0-1.5h9a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 10 4.25V1.5H5.75a.25.25 0 0 0-.25.25v2.5a.75.75 0 0 1-1.5 0Zm1.72 4.97a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734l1.47-1.47-1.47-1.47a.75.75 0 0 1 0-1.06ZM3.28 7.78 1.81 9.25l1.47 1.47a.751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Zm8.22-6.218V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"/></svg></span> <a href=https://github.com/sbamin/code101/tree/main/confs/hpc/mambaforge/envs>/confs/hpc/mambaforge/envs</a> for example scripts.</p> <h2 id=done>Done!<a class=headerlink href=#done title="Permanent link">&para;</a></h2> <p>Hope you have found this documentation helpful. I think this is more technical that I originally expected and you may have to look into stackoverflow or elsewhere to understand jargons I used across pages. Hopefully, I can go through some of sections again and put emphasis on rationale behind setting up my linux environment.</p> <p>That said, I hope this documentation, at least the CPU part, should get you started with HPC setup. For learning specific programming language and data analysis, I will post a few external resources on getting started guide to learn programming in Python, R, and more.</p> <p>Best wishes! <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M23 10a2 2 0 0 0-2-2h-6.32l.96-4.57c.02-.1.03-.21.03-.32 0-.41-.17-.79-.44-1.06L14.17 1 7.59 7.58C7.22 7.95 7 8.45 7 9v10a2 2 0 0 0 2 2h9c.83 0 1.54-.5 1.84-1.22l3.02-7.05c.09-.23.14-.47.14-.73v-2M1 21h4V9H1v12Z"/></svg></span> <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m13.13 22.19-1.63-3.83c1.57-.58 3.04-1.36 4.4-2.27l-2.77 6.1M5.64 12.5l-3.83-1.63 6.1-2.77C7 9.46 6.22 10.93 5.64 12.5M19.22 4c.28 0 .53 0 .74.05.17 1.39-.02 4.25-3.3 7.53-1.7 1.71-3.73 3.02-6.01 3.89l-2.15-2.1c.92-2.31 2.23-4.34 3.92-6.03C15.18 4.58 17.64 4 19.22 4m0-2c-1.98 0-4.98.69-8.22 3.93-2.19 2.19-3.5 4.6-4.35 6.71-.28.75-.09 1.57.46 2.13l2.13 2.12c.38.38.89.61 1.42.61.23 0 .47-.06.7-.15A19.1 19.1 0 0 0 18.07 13c5.66-5.66 3.54-10.61 3.54-10.61S20.7 2 19.22 2m-4.68 7.46c-.78-.78-.78-2.05 0-2.83s2.05-.78 2.83 0c.77.78.78 2.05 0 2.83-.78.78-2.05.78-2.83 0m-5.66 7.07-1.41-1.41 1.41 1.41M6.24 22l3.64-3.64c-.34-.09-.67-.24-.97-.45L4.83 22h1.41M2 22h1.41l4.77-4.76-1.42-1.41L2 20.59V22m0-2.83 4.09-4.08c-.21-.3-.36-.62-.45-.97L2 17.76v1.41Z"/></svg></span></p> <div class=footnote> <hr> <ol> <li id=fn:diff_bash_env> <p>There could be a difference though if both HPCs do not share common OS or they are using different system defaults, e.g., loading different bash env from <code>/etc/profile</code> which is managed by HPC staff.&#160;<a class=footnote-backref href=#fnref:diff_bash_env title="Jump back to footnote 1 in the text">&#8617;</a></p> </li> <li id=fn:rlibs> <p><a href=../../cpu/sumner_2/#install-r-libraries>Installing common packages in yoda env</a> and <a href=../../cpu/sumner_2/#install-essentials>installing essentials</a>.&#160;<a class=footnote-backref href=#fnref:rlibs title="Jump back to footnote 2 in the text">&#8617;</a></p> </li> <li id=fn:warnrpkg> <p>See <a href=#create-a-gpu-env-rey>warning box above</a> on why our setup can still update R packages managed by <em>yoda</em> env despite using custom Renviron file.&#160;<a class=footnote-backref href=#fnref:warnrpkg title="Jump back to footnote 3 in the text">&#8617;</a></p> </li> </ol> </div> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2022-08-28T08:54:44-04:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2022-08-28</span> </small> </div> <div class=md-source-date> <small> <a href=https://github.com/sbamin/code101/blob/scratch/web/docs/hpc/gpu/winter_1.md title="Requires a valid access to github repository">Contributors</a>: <span class="git-page-authors git-authors">Samir B Amin</span> </small> </div> <p><small>Author: <a href=https://sbamin.com/about rel=me>Samir B. Amin</a> <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span><a href=https://twitter.com/sbamin>@sbamin</a></small></p> <h2 id=__comments>Comments</h2> <p>Comments are powered by <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path fill-rule=evenodd d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg></span> <a href=https://github.com/sbamin/code101/issues>GitHub issues</a> and requires a login with a github id.</p> <script src=https://utteranc.es/client.js repo=sbamin/code101 issue-term=title label="site issues :speech_balloon:" theme=github-light crossorigin=anonymous async>
		</script> <!-- Reload on palette change --> <script>
	var palette = __md_get("__palette")
	if (palette && typeof palette.color === "object")
	  if (palette.color.scheme === "slate") {
	  	
	    	var utterances = document.querySelector("script[src*=utteranc]")
	    	utterances.setAttribute("theme", "github-dark")
	    
	  }

	/* Register event handlers after documented loaded */
	document.addEventListener("DOMContentLoaded", function() {
	  var ref = document.querySelector("[data-md-component=palette]")
	  ref.addEventListener("change", function() {
	    var palette = __md_get("__palette")
	    if (palette && typeof palette.color === "object") {
	    	// reload theme for either giscus or utterances
	    	
				/* Instruct Utterances to change theme */
				// https://github.com/utterance/utterances/issues/549#issuecomment-907606127
				var frame = document.querySelector(".utterances-frame")
				var theme = palette.color.scheme === "slate" ? "github-dark" : "github-light"
				const message = {
					type: 'set-theme',
					theme: theme
				};
      	  		const iframe = document.querySelector('.utterances-frame');
      	  		iframe.contentWindow.postMessage(message, 'https://utteranc.es');
			
	    }
	  })
	})
	</script> </article> </div> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../cpu/sumner_3/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Part 3" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Part 3 </div> </div> </a> <a href=../image_analysis_cellprofiler_cellpose/ class="md-footer__link md-footer__link--next" aria-label="Next: Image analysis on GPU-based HPC" rel=next> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Image analysis on GPU-based HPC </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <!-- Copyright and theme information --> <div class=md-copyright> <div class=md-copyright__highlight> &copy; 2003-2023: <a href=https://sbamin.com title=Home>SBAmin.com</a> | <a href=/disclosure/ >Disclosure</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> via <a href=https://github.com/sbamin/sitebuilder/releases target=_blank>sitebuilder 1.5.2b1_arm64</a> </div> <div class=md-social> <a href=https://sbamin.com/about target=_blank rel=noopener title=sbamin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M10.561 8.073a6.005 6.005 0 0 1 3.432 5.142.75.75 0 1 1-1.498.07 4.5 4.5 0 0 0-8.99 0 .75.75 0 0 1-1.498-.07 6.004 6.004 0 0 1 3.431-5.142 3.999 3.999 0 1 1 5.123 0ZM10.5 5a2.5 2.5 0 1 0-5 0 2.5 2.5 0 0 0 5 0Z"/></svg> </a> <a href=https://twitter.com/sbamin target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/samiramin/ target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href=https://github.com/sbamin target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://sbamin.com/contact target=_blank rel=noopener title=sbamin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M64 112c-8.8 0-16 7.2-16 16v22.1l172.5 141.6c20.7 17 50.4 17 71.1 0L464 150.1V128c0-8.8-7.2-16-16-16H64zM48 212.2V384c0 8.8 7.2 16 16 16h384c8.8 0 16-7.2 16-16V212.2L322 328.8c-38.4 31.5-93.7 31.5-132 0L48 212.2zM0 128c0-35.3 28.7-64 64-64h384c35.3 0 64 28.7 64 64v256c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V128z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "navigation.top", "navigation.indexes", "navigation.footer", "toc.follow", "content.code.annotate", "content.code.copy", "content.action.edit", "content.action.view", "header.autohide", "search.suggest", "search.highlight", "search.share"], "search": "../../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src=../../../assets/javascripts/bundle.78eede0e.min.js></script> <script src=../../../js/timeago.min.js></script> <script src=../../../js/timeago_mkdocs_material.js></script> <script src=../../../assets/js/extra.js></script> <script src=../../../assets/js/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/tablesort/5.2.1/tablesort.min.js></script> <script src=../../../assets/js/tables.js></script> </body> </html>